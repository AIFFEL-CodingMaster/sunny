{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./preprocessing.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "#mat삭제\n",
    "def delete_mat(data_list):\n",
    "    for i, data in enumerate(data_list):\n",
    "        basename = os.path.basename(data)\n",
    "        _, file = basename.split(\".\")\n",
    "        \n",
    "        if file ==\"mat\":\n",
    "            del data_list[i]\n",
    "    return data_list\n",
    "\n",
    "#4 channel 삭제\n",
    "def delete_4_channel(data_list):\n",
    "    for i, data in enumerate(data_list):\n",
    "        image_data = Image.open(data)\n",
    "        mode = image_data.mode\n",
    "        \n",
    "        if mode != \"RGB\":\n",
    "            del data_list[i]\n",
    "    return data_list\n",
    "\n",
    "#라벨 인코딩\n",
    "def label_encording(data_list):\n",
    "    #방법1\n",
    "    class_list = []\n",
    "    for data in data_list:\n",
    "        basename = os/path.basename(data)\n",
    "        label = os.path.splitext(basename)[0]\n",
    "        \n",
    "        label = re.sub(\"_\\d+\", \"\", label)\n",
    "        \n",
    "        if label in class_list:\n",
    "            continue\n",
    "        else:\n",
    "            class_list.append(label)\n",
    "    class_to_index = {cls: i for i, cls in enumerate(clsaa_list)}\n",
    "    return class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./make_tfrecord.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./make_tfrecord.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "class MakeTFRecord:\n",
    "    IMG_SIZE = 224\n",
    "    \n",
    "    def __init__(self, data_list, tfr_path, data_class):\n",
    "        self.data_list = data_list\n",
    "        self.tfr_path = tfr_path\n",
    "        self.data_class = data_class\n",
    "        \n",
    "    def _make_tf_writer(self):\n",
    "        '''\n",
    "        TF writer를 만드는 함수\n",
    "        '''\n",
    "        writer = tf.io.TFRecordWriter(self.tfr_path)\n",
    "        return writer\n",
    "    \n",
    "    # The following functions can be used to convert a value to a type compatible\n",
    "    # with tf.Example.\n",
    "    @staticmethod\n",
    "    def _bytes_feature(value):\n",
    "        \"\"\"returns a bytes_list from a string / byte.\"\"\"\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy() # Byteslist won't unpack a string from an EagerTensor\n",
    "        return tf.train.Feature(float_list = tf.train.FloatList(value=[value]))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _float_feature(value):\n",
    "        \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "        return tf.train.Feature(float_list = tf.train.FloatList(value=[value]))\n",
    "    \n",
    "    def _int64_feature(value):\n",
    "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "    def _make_tfrecord(self):\n",
    "        writer = self._make_tf_writer()\n",
    "        n = 0\n",
    "        \n",
    "        for data in self.data_list:\n",
    "            image = Image.open(data)\n",
    "            image = image.resize((self.IMG_SIZE, self.IMG_SIZE))\n",
    "            #tf record byte로 되어 있음\n",
    "            image_to_byte = image.tobytes()\n",
    "            \n",
    "            basename = os.path.basename(data)\n",
    "            label = os.path.splitext(basename)[0]\n",
    "            labe = re.sub(\"_\\d+\",\"\", label)\n",
    "            label_num = self.data_class[label]\n",
    "            \n",
    "            example = tf.train.Example(feature=tf.train.Features(feature={\n",
    "                \"image\" : self._bytes_feature(image_to_byte),\n",
    "                \"label\" : self._int64_feature(label_num)\n",
    "                                \n",
    "            }))\n",
    "            \n",
    "            writer.write(exaple.SerializeToString())\n",
    "            n += 1\n",
    "        writer.close()\n",
    "        print(f\"{n}개의 데이터, TFRecord 완선 !!!\")\n",
    "        \n",
    "    @classmethod\n",
    "    def change_img_size(cls, image_size):\n",
    "        cls.IMG_SIZE = image_size\n",
    "        \n",
    "    def __call__(self):\n",
    "        print(\"tfrecord 만들기 시작\")\n",
    "        self._make_tfrecord()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./main.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from make_tfrecord import MakeTFRecord\n",
    "from preprocessing import delete_4_channel, label_encording\n",
    "\n",
    "def preprocessing_1(data_path):\n",
    "    data_path = data_pathh + \"*\"\n",
    "    data_list = glob(data_path)\n",
    "    \n",
    "    #전처리\n",
    "    data_list = delete_mat(data_list)\n",
    "    data_list = delete_4_ckannel(data_list)\n",
    "    \n",
    "    data_class = label_encording(data_list)\n",
    "    return data_list, data_class\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", choices=['tfr', 'train','test'], help=\"TFRecord만들기 or 모델 학습 or 모델 테스트\")\n",
    "    parser.add_argument(\"--data_path\", type=str, default=\".\\\", help=\"데이터가 들어있는 디렉토리 경로\")\n",
    "    parser.add_argument(\"--tfr_path\", type=str, default=\".\\\", help=\"tfrecord 가 저장될 디렉토리\")\n",
    "    parser.add_argument(\"--img_size\", type=int, default=224, help=\"이미지 사이즈 입력\")\n",
    "    args = parser.parse_args()\n",
    "                        \n",
    "    if args.mode == \"tfr\":\n",
    "        data_list, data_class = proprocessing_1(args.data_path)\n",
    "                        \n",
    "        IMG_SIZE = args.img_size\n",
    "        tfrecord = MakeTFRecord(\n",
    "            data_list = data_list,\n",
    "            tfr_path = args.tfr_path,\n",
    "            data_class = data_class\n",
    "        )\n",
    "                        \n",
    "        if args.img_size !=224:\n",
    "            tfrecord.change_img_size(args.img_size)\n",
    "        #tfrecord 만들기\n",
    "        tfrecord()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./dataloader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./dataloader.py\n",
    "\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "class TFRecordLoader:\n",
    "    \n",
    "    def __init__(self, tfrecord_path, img_size, n_class, train_size_rate, batch_size):\n",
    "        self.tfrecord = tfrecord_path\n",
    "        self.img_size = img_size\n",
    "        self.n_class = n_class\n",
    "        self.train_size_rate = train_size_rate\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    ## tfrecord file을 data로 parsing해주는 function\n",
    "    def _parse_function(self, tfrecord_serialized):\n",
    "        features={'image': tf.io.FixedLenFeature([], tf.string),\n",
    "                 'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "                 }\n",
    "        parser_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "        \n",
    "        image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "        image = tf.reshape(image, [self.img_size, self.img_size, 3])\n",
    "        #image = tf.cast(image, tf.float32)/255.\n",
    "        \n",
    "        label = tf.cast(paesed__features['label'], tf.int64)\n",
    "        label = tf.one_hot(label, self.n_class)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def make_daraset(self):\n",
    "        \n",
    "        dataset = tf.data.TFRecordDataset(self.tfrecord)\n",
    "        dataset = dataset.map(\n",
    "            self._parse_function,\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "                    )\n",
    "        \n",
    "        train_size = int(float(self.train_size_rate * len(list(dataset))))\n",
    "        val_size = int(float((1 - self.train_size_rate)* len(list(dataset))))\n",
    "        \n",
    "        buffer_size = len(list(dataset))\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "        \n",
    "        train = dataset.take(train_size)\n",
    "        train = train.batch(self.batch_size)\n",
    "        train = train.repeat()\n",
    "        train = train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        #수정필요\n",
    "        #train dataset 만큼 스킵\n",
    "        dataset = dataset.skip(train_size)\n",
    "        #validation 크기만큼 데이터를 가져옴\n",
    "        valid = dataset.take(val_size)\n",
    "        #batch dataset으로 만들기\n",
    "        valis  valis.batch(self.batch_size)\n",
    "        \n",
    "        steps = math.floor(buffer_size / self.batch_size)\n",
    "        \n",
    "        return train, valid, steps\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
